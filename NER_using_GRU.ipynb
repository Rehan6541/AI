{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rehan6541/AI/blob/main/NER_using_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKgTzowYjk5u"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample traning setences(tokenized manually)\n",
        "#There are example sentences for tranining.Each Setence is tokenized(split into words).\n",
        "train_sentences = [\n",
        "    [\"John\",\"lives\",\"in\",\"New\",\"York\"],\n",
        "    [\"Alice\",\"is\",\"from\",\"Paris\"],\n",
        "    [\"Berlin\",\"is\",\"the\",\"capital\",\"of\",\"Germany\"]\n",
        "]"
      ],
      "metadata": {
        "id": "RW67GXF0l7rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Corresponding NER tags for training data\n",
        "#Corresponding NER (Named Entity Recognition) tags for each word\n",
        "#B-PER:Beginning of a person entity.\n",
        "#B-LOC:Beginning of a location entity\n",
        "#O: Outside,meaning no entity\n",
        "train_ner_tags = [\n",
        "    ['B-PER','O','O','B-LOC','B-LOC'],\n",
        "    ['B-PER','O','O','B-LOC'],\n",
        "    ['B-PER','O','O','O','O','B-LOC']\n",
        "]\n",
        "\n",
        "# Vocabulary and tag mapping (for tokenization)\n",
        "vocab = { \"John\":1,\"lives\":2,\"in\":3,\"New\":4,\"York\":5,\"Alice\":6,\"is\":7,\"from\":8,\"Paris\":9,\"Berlin\":10,\"the\":11,\"capital\":12,\"of\":13,\"Germany\":14}\n",
        "tags = {\"O\":0,\"B-LOC\":1,\"B-PER\":2}\n",
        "\n",
        "#The vocab dictionary maps rach word in the trainning sentence to a unique integer.\n",
        "#This is needed because the nural network dosent operate on words but on numeric values.\n",
        "#The tags dictionary maps each NER tag to an integer (0 for O , 1 for B-LOC, 2 for B-PER).\n",
        "\n",
        "#Tokenize the setence and labels\n",
        "tokenized_train_sentences = [[vocab[word] for word in sentence] for sentence in train_sentences]\n",
        "tokenized_train_ner_tags = [[tags[tag] for tag in ner] for ner in train_ner_tags]"
      ],
      "metadata": {
        "id": "plFT8qCjmgvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This converts the training senteneces and NER tags into lists of integers, using the mapping from\n",
        "#Senetence : [\"John\",\"lives\",\"in\",\"New\",\"York\"] becomes [1,2,3,4,5].\n",
        "\n",
        "\n",
        "#Extend vocabulary to include new tezt words\n",
        "vocab.update({\n",
        "    \"Marry\":15,\"visited\":16,\"London\":17,\"Tom\":18,\"moved\":19,\"to\":20,\"statue\":21\n",
        "    })\n",
        "#Here, we extend the vocabulary to include additional words from the test senteneces.\n",
        "#For example,\"Marry\" is mapped to 15,\"London\" to 17, etc.\n",
        "\n",
        "#Tokenize the test sentences\n",
        "test_sentences = [\n",
        "    [\"Marry\",\"visited\",\"London\"],\n",
        "    [\"Tom\",\"moved\",\"to\",\"Berlin\"],\n",
        "    [\"The\",\"statue\",\"is\",\"in\",\"Paris\"]\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "37LaM-b-peoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_test_sentences = [[vocab.get(word,0) for word in sentence] for sentence in test_sentences]\n",
        "#The 0 in vocab.get(word,0) serves as the default value returned\n",
        "#if a word is not found in the vocab dictionary.Here's How it works:\n",
        "\n",
        "#Vocab.get(word,0) looks up word in the vocab dictionary.\n",
        "#If the word exists in vocab, it returns its corresponding value(likely a token or index).\n",
        "#If the word does not exist in vocab, it returns - as a fallback.\n"
      ],
      "metadata": {
        "id": "SoSoCdkyrrS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters\n",
        "vocab_size = len(vocab) + 1 #Updates vocab_size to account for all words in the vocab\n",
        "embedding_dim = 64  #Dimension of enbedding vectors\n",
        "n_tags = len(tags)  #Number of entity tags\n",
        "max_len = 6 #Max sentence length(after padding)\n",
        "#vocab_size : Total number of uniqu words in the vocabulary (plus 1 for padding).\n",
        "#Embedding_dim : The number of NER tags (O, B-LOC,B-PER).\n",
        "#max_len:Maximum sentence length for paddingg.\n",
        "#Padding training and test sequences\n",
        "tokenized_train_sentences = pad_sequences(tokenized_train_sentences,maxlen=max_len,padding = 'post')\n",
        "tokenized_train_ner_tags = pad_sequences(tokenized_train_ner_tags,maxlen = max_len,padding=\"post\")\n",
        "tokenized_test_sentences = pad_sequences(tokenized_test_sentences,maxlen = max_len,padding=\"post\")\n",
        "\n",
        "#Split the training data(train/test split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(tokenized_train_sentences, tokenized_train_ner_tags, test_size = 0.2)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8TqWJl_FtC7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Creation\n",
        "model = Sequential()\n",
        "\n",
        "#Embedding layer adjusted to the correct vocab_size\n",
        "model.add(Embedding(input_dim = vocab_size, output_dim = embedding_dim, input_length = max_len))\n",
        "\n",
        "model.add(Bidirectional(GRU(units = 64, return_sequences = True))) #Bidirectiional GRU\n",
        "model.add(TimeDistributed(Dense(n_tags, activation = \"softmax\")))\n",
        "#Optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "\n",
        "#Compile model\n",
        "model.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\",metrics = [\"accuracy\"])\n",
        "\n",
        "#TRain the model\n",
        "history = model.fit(X_train, y_train, batch_size = 32, epochs = 10, validation_split = 0.2)\n",
        "\n",
        "#Evaluate the model on test data\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "FRq-op3Au8vu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e256e0c9-d985-42f3-ed6e-1d579fa2978f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.3333 - loss: 1.1029 - val_accuracy: 0.6667 - val_loss: 1.0951\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.8333 - loss: 1.0857 - val_accuracy: 0.5000 - val_loss: 1.0916\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.8333 - loss: 1.0688 - val_accuracy: 0.5000 - val_loss: 1.0882\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6667 - loss: 1.0520 - val_accuracy: 0.5000 - val_loss: 1.0849\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.6667 - loss: 1.0353 - val_accuracy: 0.5000 - val_loss: 1.0815\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6667 - loss: 1.0184 - val_accuracy: 0.5000 - val_loss: 1.0781\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6667 - loss: 1.0012 - val_accuracy: 0.5000 - val_loss: 1.0746\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.6667 - loss: 0.9835 - val_accuracy: 0.5000 - val_loss: 1.0710\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.6667 - loss: 0.9654 - val_accuracy: 0.5000 - val_loss: 1.0674\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6667 - loss: 0.9467 - val_accuracy: 0.5000 - val_loss: 1.0638\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6667 - loss: 1.0127\n",
            "Test Accuracy: 0.6666666865348816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict on new test seentences\n",
        "predictions = model.predict(tokenized_test_sentences)\n",
        "\n",
        "#Decoding the predictions back to NER tags\n",
        "reverse_tags = {i: tag for tag, i in tags.items()}\n",
        "\n",
        "'''\n",
        "Purpose of reverse_tags:\n",
        "Orgiginal tags ditionary: This typically maps tags(e.g labels, classes)\n",
        "to unique numerical ID's or indices.\n",
        "Example:tags = {'NOUN':1,'VERB': 2, 'ADJ': 3}\n",
        "Reversed reverse_tags dictionary:The reverse dictionary swaps the roles,\n",
        "mapping the numerical ID's or indices back to their corresponding tags.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "vHHGjffZvDPy",
        "outputId": "8814c229-219f-46e6-a5d0-0516368289c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nPurpose of reverse_tags:\\nOrgiginal tags ditionary: This typically maps tags(e.g labels, classes)\\nto unique numerical ID's or indices.\\nExample:tags = {'NOUN':1,'VERB': 2, 'ADJ': 3}\\nReversed reverse_tags dictionary:The reverse dictionary swaps the roles,\\nmapping the numerical ID's or indices back to their corresponding tags.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_predictions(preds, max_len):\n",
        "  decoded_preds = []\n",
        "#This list will store the decoded predictions for all sentences.\n",
        "#Iterating over each prediction (pred) for every token in each sentence\n",
        "  for pred in preds:\n",
        "    decoded_sentence = [reverse_tags[np.argmax(p)] for p in pred]\n",
        "#pred represents the list of predicted probabilities for a token.\n",
        "#For each token p, we apply np.argmax(p) to get the index of the highest probability.\n",
        "#This tells us which NER tag has the highest probability.\n",
        "#For example, if the probabilities for a token are [0.1, 0.8, 0.1],\n",
        "#then np.argmax(p) returns 1 (because 0.8 is the highest value),\n",
        "# which corresponds to the tag B-LOC (from reverse_tags).\n",
        "#We use reverse_tags[np.argmav(n\\l t lank un the artual tag (like \"O\", \"B-LOC\", or \"B-PER\")\n",
        "#based on the index returned by np.argmax(p)\n",
        "    decoded_preds.append(decoded_sentence)\n",
        "  return decoded_preds\n",
        "#Suppose the preds for one sentence look like this (simplified to one token per sentence for clai\n",
        "#preds = [\n",
        "#       [[0.2, 0.7, 0.1], [0.9, 0.05, 0.05], [0.1, 0.2, 0.7]] # Probabilities for three tokens\n",
        "\n",
        "#The model output probabilities for three tokens (one for each possible NER tag):\n",
        "\n",
        "#For token 1: [0.2, 0.7, 0.1] > highest probability is at index 1 + B-LOC.\n",
        "#For token 2: [0.9, 0.05, 0.05] + highest probability is at index 0 + 0.\n",
        "#For token 3: [0.1, 0.2, 0.7] + highest probability is at index 2 + B-PER.\n",
        "#After decoding, you get\n",
        "#decoded_sentence=['B-LOC','O','B-PER']\n",
        "\n",
        "#Decoding predictions\n",
        "decoded_predictions = decode_predictions(predictions, max_len)\n",
        "\n",
        "#Show test sentences with predicted tags\n",
        "for sentence,pred_tags in zip(test_sentences,decoded_predictions):\n",
        "  print(f\"Sentence: {' '.join(sentence)}\")\n",
        "  print(f\"Predicted NER Tags: {pred_tags}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "FtHrgdSdysQs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6669ad0f-cd97-48f4-dd36-ce3a963266ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: Marry visited London\n",
            "Predicted NER Tags: ['O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "Sentence: Tom moved to Berlin\n",
            "Predicted NER Tags: ['O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "Sentence: The statue is in Paris\n",
            "Predicted NER Tags: ['O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n"
          ]
        }
      ]
    }
  ]
}