{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM18mfetAeQecyIVhoxuU8A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rehan6541/AI/blob/main/Language_translation_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0Hbap2QnmPZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input,LSTM,Dense,Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Dataset Definition\n",
        "\n",
        "This is dataset where each tuple consists of a simple English phrase and its French translation.This is a small toy dataset for the purpose of demonstration"
      ],
      "metadata": {
        "id": "HSm88YproYvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (\"hello\", \"bonjour\"),\n",
        "    (\"how are you\", \"comment ça va\"),\n",
        "    (\"thank you\", \"merci\"),\n",
        "    (\"good morning\", \"bonjour\"),\n",
        "    (\"good night\", \"bonne nuit\"),\n",
        "    (\"see you later\", \"à plus tard\"),\n",
        "    (\"I love you\", \"je t'aime\"),\n",
        "]"
      ],
      "metadata": {
        "id": "A1wkYw-soXpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Text Preparation\n",
        "\n",
        "zip(*data): Separates the data tuples into two separate lists: one for input_texts (English) and one for target_texts (French)."
      ],
      "metadata": {
        "id": "TSomaNd_rZ2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts,target_texts = zip(*data)"
      ],
      "metadata": {
        "id": "cr2A3YSqqB0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Tokenization\n",
        "\n",
        "Tokenizer(): Creates a tokenizer that will convert text into sequences of integers.\n",
        "\n",
        "fit_on_texts(): This method creates a vocabulary from the input_texts and target_texts and assigns a unique integer to each word."
      ],
      "metadata": {
        "id": "AnisvR4EqsHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tokenizer = Tokenizer()\n",
        "target_tokenizer=Tokenizer()\n",
        "\n",
        "input_tokenizer.fit_on_texts(input_texts)\n",
        "target_tokenizer.fit_on_texts(target_texts)"
      ],
      "metadata": {
        "id": "-cPPW4RGrBAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "texts_to_sequences(): Converts each text (sentence) into a sequence of integers. Each word in the text is\n",
        "replaced by its corresponding integer from the vocabulary."
      ],
      "metadata": {
        "id": "pZcIkP1ZsH46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n",
        "target_sequences = target_tokenizer.texts_to_sequences(target_texts)\n"
      ],
      "metadata": {
        "id": "1inYQitzsEzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Vocabulary and Sequence Length Calculation\n",
        "\n",
        "word_index: This dictionary holds the integer mappings for each word. We add 1 to account for the 0-based indexing of sequences.\n",
        "\n",
        "input_vocab_size and target_vocab_size: Store the size of the vocabulary for the input and target languages."
      ],
      "metadata": {
        "id": "xal3SVwjslw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
        "target_vocab_size = len(target_tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "ClqL2G_fsSuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "max_input_len and max_target_len:store the maximum length of sequences in the input and target languages,respectively.This helps with padding the sequences to a uniform length"
      ],
      "metadata": {
        "id": "KdyddelZtNJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_len = max(len(seq) for seq in input_sequences)\n",
        "max_target_len = max(len(seq) for seq in target_sequences)"
      ],
      "metadata": {
        "id": "zfgg9v43srHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6:Padding Sequence\n",
        "\n",
        "pad_sequence():Pads each sequence to ensure that all sequence have the same length.Padding is applied to the end of the sequences (padding=\"post\")"
      ],
      "metadata": {
        "id": "or9aHsauuHb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_data = pad_sequences(input_sequences,maxlen=max_input_len,padding=\"post\")\n",
        "decoder_input_data = pad_sequences(target_sequences,maxlen=max_target_len,padding=\"post\")"
      ],
      "metadata": {
        "id": "DqJ9oPFtuGO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "q54Y2FLKs80v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7 : One-Hot Encoding Target Sequences\n",
        "np.zeros():Creates a zero matrix where each row corresponds to a sentence and each column corresponding to a time step in sequence .The depth correspondes to the size of the vacab (for on hot encoding )\n",
        "\n",
        "for loop:Lops over the target sequneces and creates onehot encoded verctors where only the index corresponding to the word is 1. The shift by one ensures that data starts predicting from the second word."
      ],
      "metadata": {
        "id": "4678xKn5trsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_target_data=np.zeros((len(target_texts),max_target_len,target_vocab_size),dtype=\"float32\")\n",
        "for i,seq in enumerate(target_sequences):\n",
        "   for t,word in enumerate(seq):\n",
        "    if t>0:#Target sequence shifted by one\n",
        "      decoder_target_data[i,t-1,word]=1.0"
      ],
      "metadata": {
        "id": "WTMiOwDnurn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8 : Splitting the Data\n",
        "\n",
        "train_test_split():Splits the input data(encoder and decoder inputs) and target data into training and testing\n",
        "\n",
        "sets.test_size=0.2 means 20% of the data is used for testing and 80% for training"
      ],
      "metadata": {
        "id": "Ok0ezm3AvHgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test,decoder_input_train,decoder_input_test=train_test_split(encoder_input_data,decoder_target_data,decoder_input_data,test_size=0.2)"
      ],
      "metadata": {
        "id": "-CoRlt7VtxT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 9: Model Architecture"
      ],
      "metadata": {
        "id": "bZaIRRcrxj2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#embedding_dim=128#or other value you'd like,typically 50,100, or 300\n",
        "#Define hyperparameters\n",
        "latent_dim=128#Numbers of unit in LSTM\n",
        "embedding_dim=128"
      ],
      "metadata": {
        "id": "ulszsbExxiTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input(shape=(max_input_len)):Defines the input shape for the encoder(input sentence length).\n",
        "\n",
        "Embedding():Maps the input word indices to dense vectors of size embedding_dim.\n",
        "\n",
        "LSTM():the LSTM layer processes the input embedding and returns two things the final hidden"
      ],
      "metadata": {
        "id": "dNEYJauryIHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs=Input(shape=(max_input_len,))\n",
        "encoder_embedding=Embedding(input_vocab_size,embedding_dim)(encoder_inputs)\n",
        "encoder_lstm=LSTM(latent_dim,return_state=True)\n",
        "encoder_outputs,state_h,state_c=encoder_lstm(encoder_embedding)"
      ],
      "metadata": {
        "id": "pJfUKpmlzf6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to the encoder the decoder also has an embedding layer followed by an LSTM received the encoder's final state(state_h,state_c) initilaze states for the decoding process.\n",
        "\n",
        "return_sequences=True ensures that the decoder products a sequence of outputs rather than just the last output"
      ],
      "metadata": {
        "id": "_0P0tYVwzQ4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_inputs = Input(shape=(max_target_len,)) # Changed the shape to a tuple\n",
        "decoder_embedding = Embedding(target_vocab_size, embedding_dim)(decoder_inputs)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[state_h, state_c])"
      ],
      "metadata": {
        "id": "j1y0lv1qyHFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dense layer\n",
        "\n",
        "Dense():A fully connected layer that outputs a probablity distribution over the target vocabulary(for each word in the sequence).\n",
        "\n",
        "softmax:Ensured the output is a probability distribution"
      ],
      "metadata": {
        "id": "fPMKcFXa1kn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_dense = Dense(target_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "id": "Swtq48Me1Uu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 10: Defining the model\n"
      ],
      "metadata": {
        "id": "9U16woCb2cZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Model([encoder_inputs,decoder_inputs],decoder_outputs)\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YjgeIZ8I2bLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model\n",
        "model.fit([X_train,decoder_input_train],y_train,batch_size=32,epochs=100,validation_data=([X_test,decoder_input_test],y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0WJMdVu2rKs",
        "outputId": "629d8608-4ddb-4362-e587-33b90d292653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - accuracy: 0.0667 - loss: 0.3415 - val_accuracy: 0.0000e+00 - val_loss: 1.7158\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.1333 - loss: 0.3393 - val_accuracy: 0.0000e+00 - val_loss: 1.7170\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1333 - loss: 0.3370 - val_accuracy: 0.0000e+00 - val_loss: 1.7183\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.1333 - loss: 0.3347 - val_accuracy: 0.0000e+00 - val_loss: 1.7196\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.1333 - loss: 0.3323 - val_accuracy: 0.0000e+00 - val_loss: 1.7210\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.1333 - loss: 0.3299 - val_accuracy: 0.0000e+00 - val_loss: 1.7225\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.1333 - loss: 0.3273 - val_accuracy: 0.0000e+00 - val_loss: 1.7242\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.1333 - loss: 0.3246 - val_accuracy: 0.0000e+00 - val_loss: 1.7260\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.1333 - loss: 0.3218 - val_accuracy: 0.0000e+00 - val_loss: 1.7280\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.1333 - loss: 0.3188 - val_accuracy: 0.0000e+00 - val_loss: 1.7303\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1333 - loss: 0.3157 - val_accuracy: 0.0000e+00 - val_loss: 1.7328\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.1333 - loss: 0.3123 - val_accuracy: 0.0000e+00 - val_loss: 1.7357\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.1333 - loss: 0.3087 - val_accuracy: 0.0000e+00 - val_loss: 1.7390\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.1333 - loss: 0.3048 - val_accuracy: 0.0000e+00 - val_loss: 1.7427\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.1333 - loss: 0.3007 - val_accuracy: 0.0000e+00 - val_loss: 1.7470\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.1333 - loss: 0.2962 - val_accuracy: 0.0000e+00 - val_loss: 1.7519\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1333 - loss: 0.2913 - val_accuracy: 0.0000e+00 - val_loss: 1.7576\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.1333 - loss: 0.2859 - val_accuracy: 0.0000e+00 - val_loss: 1.7643\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1333 - loss: 0.2801 - val_accuracy: 0.0000e+00 - val_loss: 1.7721\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.1333 - loss: 0.2737 - val_accuracy: 0.0000e+00 - val_loss: 1.7813\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.1333 - loss: 0.2666 - val_accuracy: 0.0000e+00 - val_loss: 1.7922\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.1333 - loss: 0.2589 - val_accuracy: 0.0000e+00 - val_loss: 1.8052\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.1333 - loss: 0.2505 - val_accuracy: 0.0000e+00 - val_loss: 1.8208\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.1333 - loss: 0.2415 - val_accuracy: 0.0000e+00 - val_loss: 1.8393\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.1333 - loss: 0.2321 - val_accuracy: 0.0000e+00 - val_loss: 1.8612\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.1333 - loss: 0.2227 - val_accuracy: 0.0000e+00 - val_loss: 1.8871\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1333 - loss: 0.2135 - val_accuracy: 0.0000e+00 - val_loss: 1.9174\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.0667 - loss: 0.2050 - val_accuracy: 0.0000e+00 - val_loss: 1.9521\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.0667 - loss: 0.1977 - val_accuracy: 0.0000e+00 - val_loss: 1.9910\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.0667 - loss: 0.1921 - val_accuracy: 0.0000e+00 - val_loss: 2.0331\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.0667 - loss: 0.1882 - val_accuracy: 0.0000e+00 - val_loss: 2.0772\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.0667 - loss: 0.1862 - val_accuracy: 0.0000e+00 - val_loss: 2.1214\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.0667 - loss: 0.1858 - val_accuracy: 0.0000e+00 - val_loss: 2.1642\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.0667 - loss: 0.1866 - val_accuracy: 0.0000e+00 - val_loss: 2.2039\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.0667 - loss: 0.1883 - val_accuracy: 0.0000e+00 - val_loss: 2.2396\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.0667 - loss: 0.1904 - val_accuracy: 0.0000e+00 - val_loss: 2.2708\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.0667 - loss: 0.1927 - val_accuracy: 0.0000e+00 - val_loss: 2.2973\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.0667 - loss: 0.1949 - val_accuracy: 0.0000e+00 - val_loss: 2.3195\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.0667 - loss: 0.1970 - val_accuracy: 0.0000e+00 - val_loss: 2.3379\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.0667 - loss: 0.1987 - val_accuracy: 0.0000e+00 - val_loss: 2.3529\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.0667 - loss: 0.2002 - val_accuracy: 0.0000e+00 - val_loss: 2.3654\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0667 - loss: 0.2014 - val_accuracy: 0.0000e+00 - val_loss: 2.3757\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.0667 - loss: 0.2022 - val_accuracy: 0.0000e+00 - val_loss: 2.3844\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0667 - loss: 0.2028 - val_accuracy: 0.0000e+00 - val_loss: 2.3920\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0667 - loss: 0.2032 - val_accuracy: 0.0000e+00 - val_loss: 2.3987\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.0667 - loss: 0.2033 - val_accuracy: 0.0000e+00 - val_loss: 2.4050\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.0667 - loss: 0.2033 - val_accuracy: 0.0000e+00 - val_loss: 2.4108\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.0667 - loss: 0.2031 - val_accuracy: 0.0000e+00 - val_loss: 2.4165\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.0667 - loss: 0.2029 - val_accuracy: 0.0000e+00 - val_loss: 2.4220\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.0667 - loss: 0.2026 - val_accuracy: 0.0000e+00 - val_loss: 2.4273\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.0667 - loss: 0.2023 - val_accuracy: 0.0000e+00 - val_loss: 2.4324\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.0667 - loss: 0.2021 - val_accuracy: 0.0000e+00 - val_loss: 2.4373\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.0667 - loss: 0.2019 - val_accuracy: 0.0000e+00 - val_loss: 2.4420\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.0667 - loss: 0.2018 - val_accuracy: 0.0000e+00 - val_loss: 2.4466\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.0667 - loss: 0.2016 - val_accuracy: 0.0000e+00 - val_loss: 2.4510\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.0667 - loss: 0.2015 - val_accuracy: 0.0000e+00 - val_loss: 2.4552\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.0667 - loss: 0.2013 - val_accuracy: 0.0000e+00 - val_loss: 2.4593\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.0667 - loss: 0.2011 - val_accuracy: 0.0000e+00 - val_loss: 2.4632\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.0667 - loss: 0.2010 - val_accuracy: 0.0000e+00 - val_loss: 2.4670\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.0667 - loss: 0.2008 - val_accuracy: 0.0000e+00 - val_loss: 2.4705\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.0667 - loss: 0.2008 - val_accuracy: 0.0000e+00 - val_loss: 2.4739\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.0667 - loss: 0.2008 - val_accuracy: 0.0000e+00 - val_loss: 2.4771\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.0667 - loss: 0.2009 - val_accuracy: 0.0000e+00 - val_loss: 2.4800\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.0667 - loss: 0.2012 - val_accuracy: 0.0000e+00 - val_loss: 2.4827\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.0667 - loss: 0.2015 - val_accuracy: 0.0000e+00 - val_loss: 2.4852\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.0667 - loss: 0.2019 - val_accuracy: 0.0000e+00 - val_loss: 2.4875\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0667 - loss: 0.2024 - val_accuracy: 0.0000e+00 - val_loss: 2.4895\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.0667 - loss: 0.2028 - val_accuracy: 0.0000e+00 - val_loss: 2.4913\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.0667 - loss: 0.2032 - val_accuracy: 0.0000e+00 - val_loss: 2.4930\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.0667 - loss: 0.2036 - val_accuracy: 0.0000e+00 - val_loss: 2.4944\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.0667 - loss: 0.2039 - val_accuracy: 0.0000e+00 - val_loss: 2.4956\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.0667 - loss: 0.2042 - val_accuracy: 0.0000e+00 - val_loss: 2.4967\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.0667 - loss: 0.2044 - val_accuracy: 0.0000e+00 - val_loss: 2.4975\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.0667 - loss: 0.2046 - val_accuracy: 0.0000e+00 - val_loss: 2.4982\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.0667 - loss: 0.2048 - val_accuracy: 0.0000e+00 - val_loss: 2.4987\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0667 - loss: 0.2050 - val_accuracy: 0.0000e+00 - val_loss: 2.4990\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0667 - loss: 0.2052 - val_accuracy: 0.0000e+00 - val_loss: 2.4992\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.0667 - loss: 0.2055 - val_accuracy: 0.0000e+00 - val_loss: 2.4992\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.0667 - loss: 0.2057 - val_accuracy: 0.0000e+00 - val_loss: 2.4991\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.0667 - loss: 0.2060 - val_accuracy: 0.0000e+00 - val_loss: 2.4989\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.0667 - loss: 0.2062 - val_accuracy: 0.0000e+00 - val_loss: 2.4985\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.0667 - loss: 0.2065 - val_accuracy: 0.0000e+00 - val_loss: 2.4981\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.0667 - loss: 0.2067 - val_accuracy: 0.0000e+00 - val_loss: 2.4976\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.0667 - loss: 0.2069 - val_accuracy: 0.0000e+00 - val_loss: 2.4970\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.0667 - loss: 0.2070 - val_accuracy: 0.0000e+00 - val_loss: 2.4963\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.0667 - loss: 0.2072 - val_accuracy: 0.0000e+00 - val_loss: 2.4956\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.0667 - loss: 0.2073 - val_accuracy: 0.0000e+00 - val_loss: 2.4950\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.0667 - loss: 0.2073 - val_accuracy: 0.0000e+00 - val_loss: 2.4943\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.0667 - loss: 0.2074 - val_accuracy: 0.0000e+00 - val_loss: 2.4937\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0667 - loss: 0.2074 - val_accuracy: 0.0000e+00 - val_loss: 2.4931\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.0667 - loss: 0.2075 - val_accuracy: 0.0000e+00 - val_loss: 2.4927\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0667 - loss: 0.2076 - val_accuracy: 0.0000e+00 - val_loss: 2.4925\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.0667 - loss: 0.2076 - val_accuracy: 0.0000e+00 - val_loss: 2.4925\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.0667 - loss: 0.2077 - val_accuracy: 0.0000e+00 - val_loss: 2.4927\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.0667 - loss: 0.2078 - val_accuracy: 0.0000e+00 - val_loss: 2.4932\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.0667 - loss: 0.2078 - val_accuracy: 0.0000e+00 - val_loss: 2.4939\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.0667 - loss: 0.2079 - val_accuracy: 0.0000e+00 - val_loss: 2.4947\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0667 - loss: 0.2079 - val_accuracy: 0.0000e+00 - val_loss: 2.4957\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.0667 - loss: 0.2079 - val_accuracy: 0.0000e+00 - val_loss: 2.4967\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.0667 - loss: 0.2078 - val_accuracy: 0.0000e+00 - val_loss: 2.4978\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a0b2ec2a140>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Purpose of Inference Model\n",
        "#after the model has been trained we need to define the interference process to actually generate transition.\n",
        "#In the training process both the encoder and decoder receive complete sequence.\n",
        "#However,during inference(prediction) ,we only have the input sequence,and the decoder must generate the output word by word one step at a time.\n",
        "#Thus we create two separate models for inferenve\n",
        "\n",
        "#Encoder Model:Converts the input sentence into internal states(hidden amd cell states) that are  passed to the decoder\n",
        "\n",
        "#Decoder Model:Takes internal states and generates the output sequence word vy word.'''\n",
        "\n",
        "\n",
        "#Define inference models for transition\n",
        "#Encoder Model->\n",
        "encoder_model=Model(encoder_inputs,[state_h,state_c])\n",
        "\n",
        "#Purpose:The encoder process the input sequence and outputs its final internal states(hidden state state_h and cell state state_c).\n",
        "#These states will be passed to the decoder during inference.\n",
        "#encoder_inputs:The input sequence for the encoder(which is padded).\n",
        "#[state_h,state_c]:The encoder's final states that the decoder will use to start generating the output sequence.\n",
        "\n",
        "\n",
        "\n",
        "#Decoder model\n",
        "decoder_state_input_h=Input(shape=(latent_dim,))\n",
        "decoder_state_input_c=Input(shape=(latent_dim,))\n",
        "#decoder_states=[decoder_state_input_h,decoder_state_input_c]:Inputsto the decoder\n",
        "#These are the hidden state(state_h) and cell state(state_c)\n",
        "#that were produced by the encoder.\n",
        "#In inference we do not have these fot the decoder.\n",
        "#so they are taken as inputs for the decoder.\n",
        "decoder_lstm_outputs,decoder_state_h,decoder_state_c=decoder_lstm(decoder_embedding,initial_state=[decoder_state_input_h,decoder_state_input_c])\n",
        "decoder_outputs=decoder_dense(decoder_lstm_outputs)\n",
        "decoder_model=Model([decoder_inputs,decoder_state_input_h,decoder_state_input_c],\n",
        "                    [decoder_outputs,decoder_state_h,decoder_state_c])\n",
        "\n",
        "#The decoder LSTM takes in the current word(embedded using the decoder_embedding layer)\n",
        "#along with the hidden and cell states(decoder_state_input_h and decoder_state_input_c)\n",
        "#as initial states\n",
        "#decoder_lstm_outputs:The LSTM output for the current time step\n",
        "#(which represents the proprabilities for each word in the vocabulary).\n",
        "#decoder_state_input_h,decoder_state_input_c:The updated hidden and cells after\n",
        "#processing the current word\n",
        "#these states will passed back to LSTM for the next time step.\n",
        "\n",
        "#The Function to decode a sequence using the trained model\n",
        "#The function takes an input sequence(from a source language,for example)\n",
        "# and uses an encoder-decoder model to generate a translated sequence (target language).\n",
        "#It performs this in an iterative manner,predicting one word at a time,\n",
        "#until it either predicts the end-of-sequence token or reaches a specified maximum length.\n",
        "def decode_sequence(input_seq):\n",
        "  #Encode the input as state vectors\n",
        "  states_value=encoder_model.predict(input_seq)\n",
        "  #input seq: This seaquence that you want to translate\n",
        "  #the encoder model process the input seaquence and returns the state value\n",
        "  #(hidden and cell states) that represents the context learned from the input seaquence\n",
        "  #these states are used as the inintial states for the decoder.\n",
        "  target_seq=np.zeros((1,1))\n",
        "  #Generate empty target sequence of length 1\n",
        "  #target_seq:This starts as an array of zeroes because at the beginning,\n",
        "  #there is no input  to the decoder.As the decoder predicts words,\n",
        "  #this array will hold the index of the word generated at the previous step.\n",
        "\n",
        "  stop_condition=False\n",
        "  decoded_sentence=\"\"\n",
        "  #decoded_senetence : An empty string that will hold the generated translation\n",
        "  #stop_condition: a flag to indicate when the decoded process should stop\n",
        "  #decoded senetence : this string will store the predicted translatipon\n",
        "  while not stop_condition:\n",
        "    #the loop continues until the translation is complete.\n",
        "    #(i.e. when the decoder generates the end token or exceed the allowed length)\n",
        "   # output_tokens,h,c=decoder_model.predict([target_seq]+states_value)\n",
        "    output_tokens,h,c=decoder_model.predict([target_seq]+states_value) # Pass states_value[0] and states_value[1] separately\n",
        "\n",
        "    #decoder_model uses the current target sequence(target_seq)\n",
        "   #and the encoder's final states(state_value) to predict the next word.\n",
        "   #output_token:The predicted probabilities of the next word.\n",
        "    #h,c:The updated hidden and cell states.These states are passes to the next iteration to ensure continuity in generating coherent sentences.\n",
        "    sampled_token_index=np.argmax(output_tokens[0,-1,:])\n",
        "    sampled_word=target_tokenizer.index_word.get(sampled_token_index,\"\")\n",
        "    #output token=[0,-1,:] :\n",
        "    #the output tokens array contains the predicted probablities for each possible word in the vocab\n",
        "    #The shape of output token is typically (batch_size,seaquence_len,vocab_size)\n",
        "    #In this case batch_size is 1, because we are decoding one senetence\n",
        "    #seaquence_length is 1 beacuse at each time step only one word is generated\n",
        "    #vocablary_size is number of possible words in the target vacabulary\n",
        "    #output_tokens[0,1,:] selects the predicted probablities of words at the current time stepfrom the vocabulary.\n",
        "    #Illustration:Suppose the vocublary has 5 words:{0:'hello',1:'world',2:'how',3:'are',4:'you',5:''}\n",
        "    #the output_tokens might look something like this:\n",
        "    #output_tokens[0,-1,:]=[0.1,0.6,0.05,0.15,0.1]\n",
        "    #sampled_token_index:np.argmax(output_tokens[0,-1,:]):\n",
        "    #np.argmax() finds the index of the highest probablity from yhe output_tokens array.\n",
        "    #in this case it will select the index 1 because the highset probability(0.6).\n",
        "    #corresponds to word world.\n",
        "    #now using the sample_token_index=1:\n",
        "    #sampled_word=target_tokenizer.index_word(1,\"\")\n",
        "    #sampled_word =\"world\"\n",
        "    #Putting it all together:\n",
        "    #After running np.argmax() the most likely words index (1 in this case ) is selected\n",
        "    #this index is then used to retericve the corresponding word('world' in this case)\n",
        "    #from the tokenizerds dictionary\n",
        "    decoded_sentence+=sampled_word+\" \"\n",
        "    #the predicted word is apended to the decoded senetnce string\n",
        "    if sampled_word==\"<end>\" or len(decoded_sentence)>max_target_len:\n",
        "      stop_condition=True\n",
        "      #The decoding process stops when the <end > token is predicted\n",
        "      #or if the senetence excdedds the maximum allowed length (max_target_len)\n",
        "      #updated target seaquence for the next iteration :\n",
        "    target_seq=np.zeros((1,1))\n",
        "    #This line creates a 2D NumPy array filled with zeroes,with shape(1,1).\n",
        "    #in the context of sequence-to-sequence models(such as machine translation)\n",
        "    #this is used to hold the token(word index) that will be fed as input into the decoder at the next time step.\n",
        "    target_seq[0,0]=sampled_token_index\n",
        "    #target_seq[0,0]=sampled_token_index:\n",
        "    #This line assigns the value of the sampled_token_index(which is the index of t he word predicted by the decoder in the prevvious step) to the target_seq.\n",
        "    #The value is placed at position [0,0] beacuse it's 1x1 array and[0,0]\n",
        "    #refers to only element in that array.\n",
        "    #sample_token_index =1 : (frpom the previous word prediction step)\n",
        "    #After this aaignmenet ,the target_seq will look like this :\n",
        "    #target_seq[0,0]=1\n",
        "    #Result : target_seq=[[1.]]\n",
        "    #Purpose :\n",
        "    #The traget_seq is used to input for the decoder at the next time step\n",
        "    #At each decoding step decoder needs to fed the token (or word)predicted\n",
        "    #in the previous time step . So this array is updated with the index of the last\n",
        "    #prdicted word(sampled_token_index) and then passed to the decoder for the next prediction\n",
        "    states_value=[h,c]\n",
        "    #The updated hidden and cell states (h and c) are passed back into the decoder\n",
        "    #To maintain the flow of information across time steps.\n",
        "  return decoded_sentence\n",
        "    #translate(sentence): This function translates a given sentence.\n",
        "    #input tokenizer.texts_to_sequences([sentence]): Converts the input sentence into a sequence of #pad sequences(): Pads the input sequence to the maximun length (since the nodel expects Inputs\n",
        "#decode sequence(): Calls the decoding function to generate the translation for the given input\n",
        "#Translate a sentence\n"
      ],
      "metadata": {
        "id": "BY9wqLc-3_30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(sentence):\n",
        "  sequence=input_tokenizer.texts_to_sequences([sentence])\n",
        "  sequence=pad_sequences(sequence,maxlen=max_input_len,padding=\"post\")\n",
        "  translation=decode_sequence(sequence)\n",
        "  return translation\n",
        "\n",
        "#Example usage :\n",
        "translated_sentence=translate(\"hello\")\n",
        "print(\"Translated Sentence:\",translated_sentence)"
      ],
      "metadata": {
        "id": "xi-pzJRlGxk3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a19ad267-45ae-4413-9250-d4423d0f158f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Translated Sentence: va nuit \n"
          ]
        }
      ]
    }
  ]
}